# SPDX-License-Identifier: AGPL-3.0-only

# NLU Model Configuration v2.1 (Unified)
# Supports both legacy fallback lists and dynamic, intent-based selection.
# This file provides backward compatibility while enabling advanced features.

# -----------------------------------
# Model Definitions
# -----------------------------------
# Each model includes both V1 fields (speed_tier, cost_tier) and V2 fields (quality_score, metrics).
# V1 mode uses only the legacy fields, V2 mode uses the enhanced metrics.
#
models:
  # --- Ollama Models (Local, Free) ---
  - name: llama3.2:3b
    provider: ollama
    capabilities:
      - reasoning
      - classification
      - sentiment
      - fast_extraction
      - code_generation
    # V1 Legacy Fields
    speed_tier: fast
    cost_tier: free
    max_tokens: 8192
    parallel_limit: 4
    temperature: 0.7
    # V2 Enhanced Fields (ignored in V1 mode)
    quality_score: 0.75
    avg_response_ms: 1200
    avg_tokens_per_second: 55
    cost_per_million_tokens:
      input: 0.0
      output: 0.0

  - name: llama3.1:8b
    provider: ollama
    capabilities:
      - reasoning
      - complex_reasoning
      - classification
      - sentiment
      - full_extraction
      - code_generation
    # V1 Legacy Fields
    speed_tier: medium
    cost_tier: free
    max_tokens: 32768
    parallel_limit: 2
    temperature: 0.7
    # V2 Enhanced Fields
    quality_score: 0.85
    avg_response_ms: 3500
    avg_tokens_per_second: 35
    cost_per_million_tokens:
      input: 0.0
      output: 0.0

  # --- Anthropic Models (API) ---
  - name: claude-3-5-haiku-latest
    provider: anthropic
    capabilities:
      - classification
      - sentiment
      - fast_extraction
      - tokenization
      - anthropic_flow
    # V1 Legacy Fields
    speed_tier: fast
    cost_tier: low
    max_tokens: 200000
    parallel_limit: 10
    temperature: 0.2
    # V2 Enhanced Fields
    quality_score: 0.75
    avg_response_ms: 600
    avg_tokens_per_second: 200
    cost_per_million_tokens:
      input: 0.25
      output: 1.25

  - name: claude-3-5-sonnet-latest
    provider: anthropic
    capabilities:
      - classification
      - sentiment
      - multi_step_analysis
      - full_extraction
      - segmentation
      - tokenization
      - fast_extraction
      - reasoning
      - code_generation
      - anthropic_flow
    # V1 Legacy Fields
    speed_tier: medium
    cost_tier: medium
    max_tokens: 200000
    parallel_limit: 5
    temperature: 0.2
    # V2 Enhanced Fields
    quality_score: 0.9
    avg_response_ms: 1800
    avg_tokens_per_second: 120
    cost_per_million_tokens:
      input: 3.00
      output: 15.00

  - name: claude-3-7-sonnet-latest
    provider: anthropic
    capabilities:
      - classification
      - sentiment
      - multi_step_analysis
      - full_extraction
      - segmentation
      - tokenization
      - fast_extraction
      - reasoning
      - complex_reasoning
      - code_generation
      - anthropic_flow
    # V1 Legacy Fields
    speed_tier: medium
    cost_tier: medium
    max_tokens: 200000
    parallel_limit: 5
    temperature: 0.2
    # V2 Enhanced Fields
    quality_score: 0.92
    avg_response_ms: 2000
    avg_tokens_per_second: 110
    cost_per_million_tokens:
      input: 3.00
      output: 15.00

  - name: claude-sonnet-4-20250514
    provider: anthropic
    capabilities:
      - classification
      - sentiment
      - multi_step_analysis
      - full_extraction
      - segmentation
      - tokenization
      - fast_extraction
      - complex_reasoning
      - code_generation
      - anthropic_flow
    # V1 Legacy Fields
    speed_tier: slow
    cost_tier: high
    max_tokens: 200000
    parallel_limit: 3
    temperature: 0.2
    # V2 Enhanced Fields
    quality_score: 0.96
    avg_response_ms: 3000
    avg_tokens_per_second: 90
    cost_per_million_tokens:
      input: 15.00
      output: 75.00

  # --- OpenAI Models (API) ---
  - name: gpt-4o
    provider: openai
    capabilities:
      - reasoning
      - complex_reasoning
      - classification
      - sentiment
      - full_extraction
      - code_generation
    # V1 Legacy Fields
    speed_tier: medium
    cost_tier: high
    max_tokens: 128000
    parallel_limit: 3
    temperature: 0.7
    # V2 Enhanced Fields
    quality_score: 0.95
    avg_response_ms: 2200
    avg_tokens_per_second: 100
    cost_per_million_tokens:
      input: 5.00
      output: 15.00

  - name: gpt-4o-mini
    provider: openai
    capabilities:
      - reasoning
      - classification
      - sentiment
      - fast_extraction
      - code_generation
    # V1 Legacy Fields
    speed_tier: fast
    cost_tier: low
    max_tokens: 128000
    parallel_limit: 5
    temperature: 0.7
    # V2 Enhanced Fields
    quality_score: 0.8
    avg_response_ms: 700
    avg_tokens_per_second: 180
    cost_per_million_tokens:
      input: 0.15
      output: 0.60

# -----------------------------------
# Selection Strategy (Unified)
# -----------------------------------
# The engine will use the first valid strategy it finds.
# For backward compatibility, V1 fallback lists are checked first.
# For new features, comment out V1 and use V2 dynamic selection.
#
selection_strategy:
  # --- V1 LEGACY STRATEGY (for backward compatibility) ---
  # If these keys are present, the engine will use a strict fallback order.
  # The engine will log a deprecation warning, encouraging migration to V2.
  primary_model: llama3.2
  fallback_models:
    - llama3.1 # More capable Ollama model for complex tasks
    - gpt-4o-mini # Fast, cost-effective OpenAI fallback
    - claude-3-5-haiku-latest # Fast Anthropic fallback
    - gpt-4o # High-quality OpenAI model
    - claude-3-5-sonnet-latest # Balanced Anthropic model
    - claude-3-7-sonnet-latest # Advanced Anthropic model
    - claude-sonnet-4-20250514 # Most capable Anthropic model
  prefer_speed: true # Prefer speed and local models
  prefer_free: true # Prefer free/local models over paid APIs

  # --- V2 DYNAMIC STRATEGY (the recommended approach) ---
  # If the legacy keys above are commented out or removed, the engine uses this.
  # Uncomment to enable dynamic, intent-based selection:
  #
  intent: CostOptimised # Choose: Balanced, CostOptimised, MaxSpeed, MaxQuality
  weights:
    Balanced:
      quality: 0.4
      speed: 0.3
      cost: 0.3
    CostOptimised:
      quality: 0.05
      speed: 0.15
      cost: 0.8
    MaxSpeed:
      quality: 0.2
      speed: 0.6
      cost: 0.2
    MaxQuality:
      quality: 0.7
      speed: 0.1
      cost: 0.2

  # Capability-specific overrides (V2)
  capability_profiles:
    anthropic_flow:
      weights:
        quality: 0.9
        speed: 0.1
        cost: 0.0
      description: "Force Anthropic for complex flow generation"

  # Common configuration (used by both V1 and V2)
  fallback_on_failure: true
  max_retries: 3
  timeout_seconds: 120 # Longer timeout for complex models

# -----------------------------------
# Performance Feedback Loop (V2 Only)
# -----------------------------------
# Enables the engine to learn from actual performance and update its metrics.
# Only used when running in V2 Dynamic Mode.
#
feedback:
  # If true, the engine will update performance metrics after each successful call.
  update_on_success: true

  # Path to a file where learned performance data is stored (e.g., performance.json).
  # This makes the engine's knowledge persistent across restarts.
  performance_db_path: "performance_db.json"

  # The weighting factor (alpha) for the exponential moving average.
  # A value closer to 1.0 gives more weight to the newest data point.
  # A value closer to 0.0 gives more weight to historical data.
  # new_avg = (alpha * new_value) + ((1 - alpha) * old_avg)
  learning_rate: 0.1

# -----------------------------------
# Provider Configurations
# -----------------------------------
providers:
  ollama:
    timeout_seconds: 60
    max_retries: 2
    authentication:
      type: "none"
    rate_limits:
      concurrent_requests: 3

  anthropic:
    timeout_seconds: 30
    max_retries: 3
    authentication:
      type: "api_key"
      header: "x-api-key"
      version_header: "anthropic-version"
      version: "2023-06-01"
    rate_limits:
      requests_per_minute: 60
      requests_per_hour: 1000
      concurrent_requests: 5

  openai:
    timeout_seconds: 30
    max_retries: 3
    authentication:
      type: "api_key"
      header: "Authorisation"
      version: "v1"
    rate_limits:
      requests_per_minute: 60
      requests_per_hour: 1000
      concurrent_requests: 5
